{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrPECol5soo7YPMTtveV+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedmahmoodiagents/Basics/blob/main/Langchain_Memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain==1.2.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uvkbJs3Crnh",
        "outputId": "ca171b15-75f8-463a-acc9-e6bea73e6556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==1.2.1\n",
            "  Using cached langchain-1.2.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain==1.2.1) (1.2.1)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain==1.2.1) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain==1.2.1) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.2.1) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.2.1) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.2.1) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.2.1) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.2.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.2.1) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.2.1) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain==1.2.1) (1.12.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain==1.2.1) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain==1.2.1) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain==1.2.1) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain==1.2.1) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain==1.2.1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain==1.2.1) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain==1.2.1) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain==1.2.1) (2.5.0)\n",
            "Using cached langchain-1.2.1-py3-none-any.whl (105 kB)\n",
            "Installing collected packages: langchain\n",
            "Successfully installed langchain-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6UL-ECUatOd"
      },
      "outputs": [],
      "source": [
        "import langchain, langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "P62ctuOYa0kl",
        "outputId": "61146369-eac4-4a2d-ac0c-36058c61b1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.2.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-huggingface --q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "77CjLQxNa5tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace"
      ],
      "metadata": {
        "id": "Gwg3PwIQbFqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass"
      ],
      "metadata": {
        "id": "ZaQVTKcPb4pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HF_TOKEN'] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEcJpSrlb7LB",
        "outputId": "3b4d26de-9039-4c83-a01e-0040b82aa000"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llmhg = ChatHuggingFace(llm=HuggingFaceEndpoint(repo_id='meta-llama/Llama-3.1-8B-Instruct'))"
      ],
      "metadata": {
        "id": "KG2e7bxPbWMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = llmhg.invoke('What is the capital of France')"
      ],
      "metadata": {
        "id": "YMAYPk-xb2XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "N4vckfxKcNJK",
        "outputId": "a6556215-87a2-474a-a80c-781b2c5c822a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The capital of France is Paris.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.chat_history import InMemoryChatMessageHistory"
      ],
      "metadata": {
        "id": "I1PqKYqFeXtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem = InMemoryChatMessageHistory()"
      ],
      "metadata": {
        "id": "Qk_1M78vehW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem.add_user_message('What is the capital of France')"
      ],
      "metadata": {
        "id": "ytA1-F9Tepb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem.add_ai_message('Paris')"
      ],
      "metadata": {
        "id": "SHr6TxGKfpV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem.add_user_message('What is the capital of Italy')"
      ],
      "metadata": {
        "id": "bbVTs0fDfBu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojb3J-b6fFmo",
        "outputId": "3b8ecc65-2c2c-4212-bfc3-0cd80bd81d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InMemoryChatMessageHistory(messages=[HumanMessage(content='What is the capital of France', additional_kwargs={}, response_metadata={}), AIMessage(content='Paris', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of Italy', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mem.messages[-1].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GG24m0OEfrM6",
        "outputId": "82e0e15d-5249-473a-e952-bbf9a3b412c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the capital of Italy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mem.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGcP74AcDq5v",
        "outputId": "4c5d5fee-14c4-4685-fbcc-0bdb85febb60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is the capital of France', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='Paris', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='What is the capital of Italy', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llmhg.invoke(mem.messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbI24rKJDvma",
        "outputId": "f3c8b13f-440e-400b-b334-9f03212a1609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Rome', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 58, 'total_tokens': 61}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ba10f-1ca2-7d00-8ce1-4a4b00e12441-0', usage_metadata={'input_tokens': 58, 'output_tokens': 3, 'total_tokens': 61})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llmhg.invoke(mem.messages[-1].content)"
      ],
      "metadata": {
        "id": "ZXDRKe20f_cg",
        "outputId": "64bcab45-7a75-420f-e461-8e792c141f99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of Italy is Rome.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 41, 'total_tokens': 49}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b9c80-3232-7430-912b-d91554dcd448-0', usage_metadata={'input_tokens': 41, 'output_tokens': 8, 'total_tokens': 49})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
        "    # For simplicity, we are still using the global 'mem' object for all sessions.\n",
        "    # In a real application, you would manage separate histories per session_id.\n",
        "    return mem\n",
        "\n",
        "# Define a prompt template that includes a placeholder for history\n",
        "# and a placeholder for the current human message.\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        MessagesPlaceholder(variable_name=\"history\"), # This placeholder will be filled by RunnableWithMessageHistory\n",
        "        (\"human\", \"{question}\"), # This is the placeholder for the current user input\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Chain the prompt with the language model.\n",
        "# The prompt will generate a list of messages that llmhg can process.\n",
        "chain_with_history_handling = prompt | llmhg\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(\n",
        "    chain_with_history_handling, # Now wrapping the chain, not just the LLM directly\n",
        "    get_session_history,\n",
        "    input_messages_key=\"question\", # This corresponds to '{question}' in the prompt\n",
        "    history_messages_key=\"history\" # This corresponds to 'MessagesPlaceholder(variable_name=\"history\")'\n",
        ")\n",
        "\n",
        "# Example of invoking with a session\n",
        "# The input to invoke should be a dictionary with the key specified by input_messages_key\n",
        "res_with_history = with_message_history.invoke(\n",
        "    {\"question\": \"What is the capital of Japan?\"}, # Pass the current message content\n",
        "    config={\"configurable\": {\"session_id\": \"my_session\"}}\n",
        ")\n",
        "\n",
        "print(res_with_history.content)\n",
        "\n",
        "# To demonstrate history working, let's ask a follow-up question in the same session\n",
        "res_with_history_followup = with_message_history.invoke(\n",
        "    {\"question\": \"And what is its population?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"my_session\"}}\n",
        ")\n",
        "\n",
        "print(res_with_history_followup.content)"
      ],
      "metadata": {
        "id": "0HKMDugVgDWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d715dc52-f67f-481c-914f-deea2045602a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokyo\n",
            "The population of Tokyo is approximately 39.1 million people (as of 2021), with its metropolitan area having a population of over 38 million people.\n"
          ]
        }
      ]
    }
  ]
}