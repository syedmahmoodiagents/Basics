{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcntSZoxE8jjqGXQqKwp94",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedmahmoodiagents/Basics/blob/main/LangChain_Session.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-Ak6idusLsLR"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-huggingface --q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace"
      ],
      "metadata": {
        "id": "MbjmG66cL_gp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_hg = ChatHuggingFace(llm=HuggingFaceEndpoint(repo_id='meta-llama/Llama-3.1-8B-Instruct'))"
      ],
      "metadata": {
        "id": "f3k2dsViMhg9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass"
      ],
      "metadata": {
        "id": "4GuhvnrnM4IT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HF_TOKEN'] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORkabjAbM-b1",
        "outputId": "ab0ea170-fe2c-4eef-e303-507c24d6c18b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_hg.invoke(\"what is the capital of France?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DryDTkjNKBu",
        "outputId": "76f37c94-034b-41dd-fabe-52d0a552c9ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 42, 'total_tokens': 50}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ba135-17c3-7153-a0bd-8d23168bcc20-0', usage_metadata={'input_tokens': 42, 'output_tokens': 8, 'total_tokens': 50})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.chat_history import InMemoryChatMessageHistory"
      ],
      "metadata": {
        "id": "k9ANtCC4NkfY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem = InMemoryChatMessageHistory()"
      ],
      "metadata": {
        "id": "ylLJbdX7NwxA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem.add_user_message(\"what is the capital of France?\")\n",
        "mem.add_ai_message(\"Paris haha hehe\")\n",
        "mem.add_user_message(\"what is the capital of Germany?\")\n",
        "mem.add_ai_message(\"Berlin haha hehe\")\n",
        "mem.add_user_message(\"By taking the examples from above answers tell us what is the capital of Italy? exactly the same way how its given in example?\")"
      ],
      "metadata": {
        "id": "A2xPoKyBN0t1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7BFHh-VOJlG",
        "outputId": "b9110088-3c95-4ece-eebc-e10af6e4554c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InMemoryChatMessageHistory(messages=[HumanMessage(content='what is the capital of France?', additional_kwargs={}, response_metadata={}), AIMessage(content='Paris haha hehe', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is the capital of Germany?', additional_kwargs={}, response_metadata={}), AIMessage(content='Berlin haha hehe', additional_kwargs={}, response_metadata={}), HumanMessage(content='By taking the examples from above answers tell us what is the capital of Italy? exactly the same way how its given in example?', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mem.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAfk9sgVONrN",
        "outputId": "cb10d620-49c5-4a5b-9f5e-0c3ec8f31505"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='what is the capital of France?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='Paris haha hehe', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='what is the capital of Germany?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='Berlin haha hehe', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='By taking the examples from above answers tell us what is the capital of Italy? exactly the same way how its given in example?', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_hg.invoke(mem.messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zn5pH9iOTFZ",
        "outputId": "5a6a02b4-5df0-4d03-876d-28bb2ed056f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Rome haha hehe', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 103, 'total_tokens': 109}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ba13c-51c8-77a1-a496-94c9f0f58fc6-0', usage_metadata={'input_tokens': 103, 'output_tokens': 6, 'total_tokens': 109})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store = {}"
      ],
      "metadata": {
        "id": "96YTX2ZdOiaY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store['David'] = InMemoryChatMessageHistory()"
      ],
      "metadata": {
        "id": "ksaUqyFePWNQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store['Harry'] = InMemoryChatMessageHistory()"
      ],
      "metadata": {
        "id": "x5e6TxdxPtf8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store['David'].add_user_message(\"what is spoken in France?\")\n",
        "store['David'].add_ai_message(\"French haha hehe?\")\n",
        "store['David'].add_user_message(\"what is spoken in Italy?\")\n",
        "store['David'].add_ai_message(\"Italian haha hehe?\")\n",
        "store['David'].add_user_message(\"what is spoken in Germany?\")"
      ],
      "metadata": {
        "id": "LMZbB2l4Px14"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_hg.invoke(store['David'].messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoqqEeEjQd4-",
        "outputId": "def3dc61-7dce-4f71-e6cb-a4ef48103e36"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='German.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 83, 'total_tokens': 86}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ba142-5381-7cb0-887e-ceaf0e5ce776-0', usage_metadata={'input_tokens': 83, 'output_tokens': 3, 'total_tokens': 86})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real Session"
      ],
      "metadata": {
        "id": "4Kn0OQqbZ1e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
      ],
      "metadata": {
        "id": "j7jawkt2T67n"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableWithMessageHistory"
      ],
      "metadata": {
        "id": "7AAXbbiUUvQz"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.chat_history import InMemoryChatMessageHistory"
      ],
      "metadata": {
        "id": "LFA04GfRXHH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an AI assistant.\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])"
      ],
      "metadata": {
        "id": "5J-Dr-asUFH-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store = {}  # store sessions here\n",
        "def get_history(session_id: str):\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryChatMessageHistory()\n",
        "    return store[session_id]"
      ],
      "metadata": {
        "id": "KhuE2SN9USwT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = RunnableWithMessageHistory(\n",
        "    runnable=template | llm_hg,\n",
        "    get_session_history=get_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\"\n",
        ")"
      ],
      "metadata": {
        "id": "sEE2xcXvUWtZ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_history('David').add_user_message(\"what is spoken in France?\")\n",
        "get_history('David').add_ai_message(\"French haha hehe?\")\n",
        "get_history('David').add_user_message(\"what is spoken in Italy?\")\n",
        "get_history('David').add_ai_message(\"Italian haha hehe?\")"
      ],
      "metadata": {
        "id": "KUqhhoMPVVXI"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_history('David')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nkbd21srYrh2",
        "outputId": "e1c8e641-8b22-4831-982c-4fda56d99fa6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InMemoryChatMessageHistory(messages=[HumanMessage(content='what is spoken in France?', additional_kwargs={}, response_metadata={}), AIMessage(content='French haha hehe?', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is spoken in Italy?', additional_kwargs={}, response_metadata={}), AIMessage(content='Italian haha hehe?', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.invoke({\"input\": \"What did I just say?\"}, config={\"configurable\": {\"session_id\": \"David\"}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xed1a1laYza4",
        "outputId": "ac4ad550-e96b-4c03-c1d7-6cd648085bff"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='You asked about the languages spoken in different countries, and I answered with the languages spoken in France and Italy. You seemed to be expecting a repetition of the question, so I repeated the country names and their languages, but in a playful way (with \"haha hehe\").', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 89, 'total_tokens': 146}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ba163-e423-7d72-82f4-ff763b259bf7-0', usage_metadata={'input_tokens': 89, 'output_tokens': 57, 'total_tokens': 146})"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = app.invoke({\"input\": \"What did I just say?\"}, config={\"configurable\": {\"session_id\": \"David\"}})"
      ],
      "metadata": {
        "id": "CdGXKn8XY-Nr"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TobepawdZV87",
        "outputId": "7bc5839c-7cfc-4693-cd6d-45c0cb788945"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='You asked what languages are spoken in France and Italy.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 89, 'total_tokens': 101}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ba166-6249-76f0-80f1-84f89890a9e8-0', usage_metadata={'input_tokens': 89, 'output_tokens': 12, 'total_tokens': 101})"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YKqVYZVYZabu",
        "outputId": "0ba8b92f-1da0-48df-dd8f-5e6220ac75c3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You asked what languages are spoken in France and Italy.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}